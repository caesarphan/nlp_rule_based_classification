{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## BANA 275: NATRL LANG PROCESS\n",
    "\n",
    "# Homework 1: Rule-Based Classification\n",
    "\n",
    "\n",
    "The first programming assignment will familiarize you with the basic text processing methods, the\n",
    "use of pre-built lexicons and rules for text classification.\n",
    "\n",
    "## 1 Task: Sentiment Classification\n",
    "\n",
    "The primary objective for the assignment is to predict the sentiment of a movie review. In particular, we\n",
    "will be providing you with a dataset containing the text of the movie reviews from IMDB, and for each\n",
    "review, you have to predict whether the review is positive or negative. We will also provide some code to\n",
    "help you read and write the output files.\n",
    "\n",
    "### 1.1 Data\n",
    "\n",
    "The primary data file is named data.zip, which contains the following:\n",
    "```\n",
    "- lexicon/: Two sentiment lexicons. The code for reading them is included.\n",
    "- test/: Folder of text files containing reviews that are not labeled.\n",
    "- train/: Folder of text files containing the reviews that are part of labeled data.\n",
    "- train.csv: List of files and associated sentiment label, for evaluating your classifier.\n",
    "\n",
    "Note: train/ and test/ folder should contain 25,000 files. If you have 25,001 on disk, remember to delete the .DS_Store or desktop.ini before running any code.\n",
    "```\n",
    "\n",
    "### 1.2 Kaggle\n",
    "\n",
    "Kaggle is a website that hosts machine learning competitions, and we will be using it to evaluate and\n",
    "compare the accuracy of your classifiers. We know the true sentiment for each of the _unlabeled_ reviews,\n",
    "which we will use to evaluate your submissions, and thus your submission file to Kaggle should contain a\n",
    "predicted label for all the unlabeled reviews. In particular, the submission file ```test.csv``` should have the following format (code already does this):\n",
    "\n",
    "- Start with a single line header: ```Fileindex, Category```\n",
    "- For each of the unlabeled speech (sorted by name) there is a line containing an increasing integer index (i.e. line number 1), then a comma, and then the string label prediction of that speech.\n",
    "- See ```test-basic.csv``` for example.\n",
    "\n",
    "You can make ***at most _three_*** submissions each day, so we encourage you to test your submission files early,\n",
    "and observe the performance of your system. By the end of the submission period, you will have to select\n",
    "the two submissions the best of which you want to be judged as your final submission. Public leaderboard uses 30% of the data while your performance is evaluated by private leaderboard that uses 70% of the data.\n",
    "\n",
    "### 1.3 Source Code\n",
    "\n",
    "Some initial code contains methods for loading the data and lexicons, and calling the methods to run and\n",
    "evaluate your classifier. It also contains the code to output the submission file from your classifier (called\n",
    "```test.csv```) that you will submit to Kaggle. Your directory structure should look like this.\n",
    "```\n",
    "hw1  \n",
    "│\n",
    "└───code\n",
    "│   └───rule-based-classification.ipynb\n",
    "└───data\n",
    "│   └───lexicon\n",
    "│       │   inqtabs.txt\n",
    "│       └───SentiWordNet_3.0.0_20130122.txt\n",
    "│   └───test\n",
    "│       │   0.txt\n",
    "│       │   1.txt\n",
    "│       │   ...   \n",
    "│       └───24999.txt\n",
    "│   └───train\n",
    "│       │   0.txt\n",
    "│       │   1.txt\n",
    "│       │   ...   \n",
    "│       └───24999.txt\n",
    "│   └───train.csv\n",
    "└───output\n",
    "    │   fn.txt\n",
    "    │   fp.txt\n",
    "    │   test.csv\n",
    "    │   tn.txt\n",
    "    └───tp.txt\n",
    "Note: You need mannually create folder 'code' and 'output'.\n",
    "```\n",
    "\n",
    "This [code block](#cb) contains the skeleton of your classifier; this is the **only** part you need to modify.\n",
    "\n",
    "## 2 What to submit?\n",
    "\n",
    "Prepare and submit a single write-up ( **PDF, maximum 2 pages** ) and a jupyter notebook to Canvas. **Do not include your student ID number** , since we might share it with the class if it’s\n",
    "worth highlighting. The write-up and code should address the following.\n",
    "\n",
    "### 2.1 Preliminaries (5 points)\n",
    "\n",
    "At the top of your write-up, include your team's Kaggle name such as '**Sec A Team 1**' , and the accuracy that your **_best_** submission obtained on Kaggle. You do **not** need to include any other details such as name, UCINet Id, etc. \n",
    "\n",
    "### 2.2 Rule-Based Classifier (40 points)\n",
    "\n",
    "Your main goal is to improve the basic classifier. For this, you should consider doing both of the following:\n",
    "\n",
    "- **Lexicons** : We have provided two lexicons for your use. Each lexicon is a dictionary containing words\n",
    "as keys and the sentiment as the value. For Harvard Inquirer [(inqtabs_dict)](http://www.wjh.harvard.edu/~inquirer/), the value is a sentiment\n",
    "label: 0 for negative and 1 for positive. For SentiWordNet [(swn_dict)](http://sentiwordnet.isti.cnr.it/), each value is a pair of positive\n",
    "and negative scores, respectively. Use them as you see fit.\n",
    "\n",
    "- **Regular Expressions** : After looking at some reviews, you may have ideas for rules on the review\n",
    "text that you think will help predict the sentiment. Implement them using if/then and regular\n",
    "expressions.\n",
    "\n",
    "Implement your suggestions in ```classify()```, and describe them in a few sentences in your\n",
    "report. The primary evaluation for this part will be the performance of your classifier, combined with how\n",
    "creative/interesting your proposed ideas are.\n",
    "\n",
    "### 2.3 Examples (30 points)\n",
    "\n",
    "In order to aid analysis, you also need to figure out the errors being made by your classifiers, i.e. split each prediction into _four_ categories: true positives, true negatives, false positives, and false negatives. If you look at ```get_error_type()```, there is an incorrect implementation of this method. Fix this code to print the appropriate examples, which will result in 4 files full of reviews, called ```fp.txt, fn.txt, tp.txt, and tn.txt```. Include 2-3 examples from the false positives and negatives in your report.\n",
    "\n",
    "### 2.4 Analysis (20 points)\n",
    "\n",
    "Analyze the above false positive and false negatives in your writeup. In particular, in a few sentences,\n",
    "describe what is lacking in your approach, i.e. why do you think the errors exist. Write a sentence or two\n",
    "about how you would address them if you had more time. You will be evaluated on how well you were able\n",
    "to identify the problems, and the creativity of your proposed future solution.\n",
    "\n",
    "\n",
    "\n",
    "## 3 Statement of Collaboration (5 points)\n",
    "\n",
    "It is **mandatory** to include a _Statement of Collaboration_ in each submission, with respect to the guidelines\n",
    "below. Include the names of everyone involved in the discussions (especially in-person ones), and what\n",
    "was discussed.\n",
    "\n",
    "All students are required to follow the academic honesty guidelines posted on the course website. For\n",
    "programming assignments, in particular, we encourage the students to organize to\n",
    "discuss the task descriptions, requirements, bugs in our code, and the relevant technical content _before_ they\n",
    "start working on it. However, you should not discuss the specific solutions, and, as a guiding principle, you\n",
    "are not allowed to take anything written or drawn away from these discussions (i.e. no photographs of the\n",
    "blackboard, written notes, etc.). Especially _after_ you have started working on the\n",
    "assignment, try to restrict the discussion on Canvas as much as possible, so that there is no doubt as to the\n",
    "extent of your collaboration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Some initial codes. Do not modify.\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "POS_LABEL = '1'\n",
    "NEG_LABEL = '0'\n",
    "\n",
    "\n",
    "def check_if_exist(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(file_path + ' could not be found')\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def extract_word(word):\n",
    "    return word.lower() if word.find('#') < 0 else word[:word.find('#')].lower()\n",
    "\n",
    "\n",
    "def read_inqtabs(input_file_path):\n",
    "    \"\"\"\n",
    "    :param input_file_path:\n",
    "    :return lexicons: dictionary of labels (e.g. lexicons['good']: 1, lexicons['bad']: 0)\n",
    "    \"\"\"\n",
    "    if not check_if_exist(input_file_path):\n",
    "        return\n",
    "\n",
    "    lexicons = dict()\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as fp:\n",
    "        for line in fp.readlines():\n",
    "            elements = line.strip().split('\\t')\n",
    "            word = extract_word(elements[0])\n",
    "            if len(word) > 0 and (elements[2] == 'Positiv' or elements[3] == 'Negativ'):\n",
    "                label = POS_LABEL if elements[2] == 'Positiv' else NEG_LABEL\n",
    "                lexicons[word] = label\n",
    "    return lexicons\n",
    "\n",
    "\n",
    "def read_senti_word_net(input_file_path):\n",
    "    \"\"\"\n",
    "    :param input_file_path:\n",
    "    :return lexicon: dictionary of lists (e.g. lexicons['good'][0]: positive score, lexicons['bad'][1]: negative score)\n",
    "    \"\"\"\n",
    "    if not check_if_exist(input_file_path):\n",
    "        return\n",
    "\n",
    "    all_lexicons = dict()\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as fp:\n",
    "        for line in fp.readlines():\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "\n",
    "            elements = line.strip().split('\\t')\n",
    "            if len(elements) < 5 or len(elements[4]) == 0:\n",
    "                continue\n",
    "\n",
    "            for tmp_word in elements[4].split(' '):\n",
    "                word = extract_word(tmp_word).replace('_', ' ')\n",
    "                if len(word) > 0 and len(elements[2]) > 0 and len(elements[3]) > 0:\n",
    "                    if word not in all_lexicons.keys():\n",
    "                        all_lexicons[word] = list()\n",
    "                        all_lexicons[word].append(list())\n",
    "                        all_lexicons[word].append(list())\n",
    "                    all_lexicons[word][0].append(float(elements[2]))\n",
    "                    all_lexicons[word][1].append(float(elements[3]))\n",
    "\n",
    "    lexicons = dict()\n",
    "    for word in all_lexicons.keys():\n",
    "        lexicons[word] = (max(all_lexicons[word][0]), max(all_lexicons[word][1]))\n",
    "    return lexicons\n",
    "\n",
    "\n",
    "def get_training_data(filedir):\n",
    "    with open(os.path.join(filedir, 'train.csv'), encoding='utf-8') as csvfile:\n",
    "        training_data = [row for row in csv.DictReader(csvfile, delimiter=',')]\n",
    "        for entry in training_data:\n",
    "            with open(os.path.join(filedir, 'train', entry['FileIndex'] + '.txt'), encoding='utf-8') as reviewfile:\n",
    "                entry['Review'] = reviewfile.read()\n",
    "    return training_data\n",
    "\n",
    "\n",
    "def get_training_accuracy(data, inqtabs_dict, swn_dict):\n",
    "    num_correct = 0\n",
    "    etype_files = {}\n",
    "    for etype in [\"fp\", \"fn\", \"tp\", \"tn\"]:\n",
    "        etype_files[etype] = open('../output/'+ etype + '.txt', 'w+', encoding='utf-8')\n",
    "    for row in data:\n",
    "        sentiment_prediction = classify(row['Review'], inqtabs_dict, swn_dict)\n",
    "        sentiment_label = int(row['Category'])\n",
    "        if sentiment_prediction == sentiment_label:\n",
    "            num_correct += 1\n",
    "        etype = get_error_type(sentiment_prediction, sentiment_label)\n",
    "        etype_files[etype].write(\"%s\\t%s\\n\"%(row['FileIndex'], row['Review']))\n",
    "    accuracy = num_correct * 1.0 / len(data)\n",
    "    for etype in [\"fp\", \"fn\", \"tp\", \"tn\"]:\n",
    "        etype_files[etype].close()\n",
    "    print(\"Accuracy: \" + str(accuracy))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def write_predictions(filedir, inqtabs_dict, swn_dict, output_file_name):\n",
    "    testfiledir = os.path.join(filedir, 'test')\n",
    "    with open(output_file_name, 'w+', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, delimiter=',', fieldnames=['FileIndex', 'Category'])\n",
    "        writer.writeheader()\n",
    "        for filename in tqdm(sorted(os.listdir(testfiledir), key=lambda x: int(os.path.splitext(x)[0]))):\n",
    "            with open(os.path.join(testfiledir, filename), encoding='utf-8') as reviewfile:\n",
    "                review = reviewfile.read()\n",
    "                prediction = dict()\n",
    "                prediction['FileIndex'] = os.path.splitext(filename)[0]\n",
    "                prediction['Category'] = classify(review, inqtabs_dict, swn_dict)\n",
    "                writer.writerow(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<a id=\"cb\"></a>\n",
    "# Code Block for you to modify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "\n",
    "\n",
    "def get_error_type(pred, label):\n",
    "    # return the type of error: tp,fp,tn,fn\n",
    "    if pred == 1 and label == 1:\n",
    "        return 'tp'\n",
    "    elif pred == 1 and label == 0:\n",
    "        return 'fp'\n",
    "    elif pred == 0 and label == 1:\n",
    "        return 'fn'\n",
    "    elif pred == 0 and label == 0:\n",
    "        return 'tn'\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "term_count = {}\n",
    "term_sentiment = {}\n",
    "\n",
    "def top_terms(text, inqtabs_dict,swn_dict): #used to update dictionary, not to be applied into 'classify' function\n",
    "    #clean up text\n",
    "    regex_clean_html = re.compile(r'<.*?>') # Remove any HTML tags\n",
    "    clean = re.sub(regex_clean_html, '', text)\n",
    "    regex = r'[A-Za-z]{3,}\\b' #You'll probably want to update this regular expression\n",
    "    words = re.findall(regex, clean) # Extract word from a text\n",
    "    \n",
    "    positive_words_inqtabs = []\n",
    "    negative_words_inqtabs = []\n",
    "    words_matched_inqtabs = []\n",
    "    positive_words_swn = {}\n",
    "    negative_words_swn = {}\n",
    "    positive_words_swn_count = []\n",
    "    negative_words_swn_count = []\n",
    "    words_matched_swn = []\n",
    "    \n",
    "    # Stopwords\n",
    "    stopword = stopwords.words('english')\n",
    "    words_lower = [x.lower() for x in words] # lower case\n",
    "    words_rm = [x for x in words_lower if x not in stopword] # remove stopwords\n",
    "    \n",
    "    for word in words_rm:\n",
    "        word = word.lower()  #You can do other preprocessing here like remove punctuation, etc\n",
    "        if word in inqtabs_dict:\n",
    "            if inqtabs_dict[word] == '1':\n",
    "                positive_words_inqtabs.append(word)\n",
    "            else:\n",
    "                negative_words_inqtabs.append(word)\n",
    "            words_matched_inqtabs.append(word)\n",
    "        if word not in inqtabs_dict and word in swn_dict:\n",
    "            positive_words_swn[word] = swn_dict[word][0]\n",
    "            negative_words_swn[word] = swn_dict[word][1]\n",
    "            words_matched_swn.append(word)\n",
    "\n",
    "        \n",
    "        if word not in term_count:\n",
    "            term_count[word] = 1\n",
    "        else:\n",
    "            term_count[word] += 1\n",
    "\n",
    "#built for inqtabs_dict\n",
    "    sorted_pos = positive_words_inqtabs\n",
    "    sorted_neg = negative_words_inqtabs\n",
    "# #built for swn_dict\n",
    "#     sorted_pos = sorted(positive_words_swn.items(), key=lambda x: x[1], reverse=True)\n",
    "#     sorted_neg = sorted(negative_words_swn.items(), key=lambda x: x[1], reverse=True)\n",
    "#     n = 20\n",
    "#     print(sorted_pos)\n",
    "#     print()\n",
    "#     print(sorted_neg)\n",
    "    \n",
    "    \n",
    "#     print(\"Positive words found: \", len(positive_words_swn), sorted(positive_words_swn.items(), key=lambda x: x[1], reverse=True))\n",
    "#     print(\"Total positive sentiment: \", sum(positive_words_swn.values()))\n",
    "#     print(\"\\nNegative words scores: \", len(negative_words_swn), sorted(negative_words_swn.items(), key=lambda x: x[1], reverse=True))\n",
    "#     print(\"Total negative sentiment:\", sum(negative_words_swn.values()))\n",
    "    return sorted_pos,sorted_neg    \n",
    "\n",
    "#Put the code under the classify method here.  Here's some code to start you off\n",
    "def classify(text, inqtabs_dict, swn_dict):\n",
    "    regex_clean_html = re.compile(r'<.*?>') # Remove any HTML tags\n",
    "    clean = re.sub(regex_clean_html, '', text)\n",
    "    regex = r'[A-Za-z]{3,}\\b' #You'll probably want to update this regular expression\n",
    "    words = re.findall(regex, clean) # Extract word from a text\n",
    "    inqtabs_dict['fun'] = 1\n",
    "#     del inqtabs_dict['get']\n",
    "    \n",
    "    aa_temp = list(swn_dict['dog'])\n",
    "    aa_temp[0],aa_temp[1] = 1,0\n",
    "    swn_dict['dog'] = tuple(aa_temp)\n",
    "    \n",
    "    aa_temp = list(swn_dict['kill'])\n",
    "    aa_temp[0],aa_temp[1] = 0,swn_dict['kill'][1]\n",
    "    swn_dict['kill'] = tuple(aa_temp)\n",
    "    \n",
    "    aa_temp = list(swn_dict['good'])\n",
    "    aa_temp[0],aa_temp[1] = swn_dict['good'][1],0\n",
    "    swn_dict['good'] = tuple(aa_temp)\n",
    "    \n",
    "    positive_words_inqtabs = []\n",
    "    negative_words_inqtabs = []\n",
    "    positive_words_inqtabs_count = 0\n",
    "    negative_words_inqtabs_count = 0    \n",
    "    \n",
    "    words_matched_inqtabs = []\n",
    "    positive_words_swn = {}\n",
    "    negative_words_swn = {}\n",
    "    positive_words_swn_count = []\n",
    "    negative_words_swn_count = []\n",
    "    words_matched_swn = []\n",
    "    \n",
    "    # Stopwords\n",
    "    stopword = stopwords.words('english') # Default English Stopwords\n",
    "    words_lower = [x.lower() for x in words] # lower case\n",
    "    words_rm = [x for x in words_lower if x not in stopword] # remove stopwords\n",
    "  \n",
    "#tokenize, pos tagging, lemmatize\n",
    "#     sentences = \" \".join(words_rm)\n",
    "#     tokens = nltk.word_tokenize(sentences)\n",
    "#     tag_map = defaultdict(lambda : wordnet.NOUN)\n",
    "#     tag_map['J'] = wordnet.ADJ\n",
    "#     tag_map['V'] = wordnet.VERB\n",
    "#     tag_map['R'] = wordnet.ADV\n",
    "#     word_list = []\n",
    "#     for token,tag in pos_tag(tokens):\n",
    "#         lemma = lemmatizer.lemmatize(token, tag_map[tag[0]])\n",
    "#         word_list.append(lemma)  \n",
    "    \n",
    "    for word in words_rm:\n",
    "        #word = word.lower()  #You can do other preprocessing here like remove punctuation, etc\n",
    "        if word in inqtabs_dict:\n",
    "            if inqtabs_dict[word] == '1':\n",
    "                positive_words_inqtabs_count += 1\n",
    "            else:\n",
    "                negative_words_inqtabs_count += 1\n",
    "            words_matched_inqtabs.append(word)\n",
    "        if (word not in inqtabs_dict and word in swn_dict):\n",
    "            positive_words_inqtabs_count += (swn_dict[word][0])**3\n",
    "            negative_words_inqtabs_count += (swn_dict[word][1])**3\n",
    "            words_matched_swn.append(word)\n",
    "\n",
    "    pos_cnt = positive_words_inqtabs_count + 1\n",
    "    neg_cnt = negative_words_inqtabs_count + 1\n",
    "    if ((pos_cnt / neg_cnt) >1.47):\n",
    "        score = 1\n",
    "    else:\n",
    "        score = 0\n",
    "\n",
    "#     print(\"Original text: \", text)\n",
    "#     print(\"Words in text: \", words)\n",
    "#     print(\"\\nScores from Lexicon 1 (Harvard Inquirer)\")\n",
    "#     print(\"Positive words found: \", len(positive_words_inqtabs), positive_words_inqtabs)\n",
    "#     print(\"Negative words found: \", len(negative_words_inqtabs), negative_words_inqtabs)\n",
    "#     print(\"\\nScores from Lexicon 2 (SentiWordNet)\")\n",
    "#     print(\"Positive words found: \", len(positive_words_swn), sorted(positive_words_swn.items(), key=lambda x: x[1], reverse=True))\n",
    "#     print(\"Total positive sentiment: \", sum(positive_words_swn.values()))\n",
    "#     print(\"\\nNegative words scores: \", len(negative_words_swn), sorted(negative_words_swn.items(), key=lambda x: x[1], reverse=True))\n",
    "#     print(\"Total negative sentiment:\", sum(negative_words_swn.values()))\n",
    "#     print(\"\\nScore: \", score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Classifying...\n",
      "Accuracy: 0.67312\n",
      "Writing output...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2719e2b6e37d4d02b133bd6b69250151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 2min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "filedir = 'C:/Users/fcbmu/OneDrive - UC Irvine/Academic 2020-21/Spring 2021/BANA 275/Python/HW 1/data'\n",
    "output_file_name = 'C:/Users/fcbmu/OneDrive - UC Irvine/Academic 2020-21/Spring 2021/BANA 275/Python/HW 1/output/test.csv'\n",
    "print(\"Reading data...\")\n",
    "data = get_training_data(filedir)\n",
    "lexicon_dir = os.path.join(filedir, 'lexicon')\n",
    "inqtabs_dict = read_inqtabs(os.path.join(lexicon_dir, 'inqtabs.txt'))\n",
    "swn_dict = read_senti_word_net(os.path.join(lexicon_dir, 'SentiWordNet_3.0.0_20130122.txt'))\n",
    "print(\"Classifying...\")\n",
    "get_training_accuracy(data, inqtabs_dict, swn_dict)\n",
    "print(\"Writing output...\")\n",
    "write_predictions(filedir, inqtabs_dict, swn_dict, output_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67312\n",
      "Wall time: 57.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.67312"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Rerun this as you make changes to the classify method \n",
    "# I strongly recommend you look at the number of false positives and false negatives after running this.\n",
    "# You can see the false positives and false negatives by looking at the size of the fp.txt and fn.txt\n",
    "# Note: you need to complete the get_error_type function to see the false positives and false negatives \n",
    "# prior to update kill and dog 0.67308\n",
    "get_training_accuracy(data, inqtabs_dict, swn_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "TP:  7650 , TN:  9178\n",
      "FP:  3322 , FN:  4850\n",
      "\n",
      "Confusion Matrix\n",
      "TP:  0.31 , TN:  0.37\n",
      "FP:  0.13 , FN:  0.19\n",
      "\n",
      "Precision:  0.7\n",
      "Recall:  0.61\n"
     ]
    }
   ],
   "source": [
    "# find your current directory\n",
    "import os\n",
    "#curDir = os.getcwd()\n",
    "#print(curDir)\n",
    "fn = open('C:/Users/fcbmu/OneDrive - UC Irvine/Academic 2020-21/Spring 2021/BANA 275/Python/HW 1/output/fn.txt','r',encoding='utf-8')\n",
    "fp = open('C:/Users/fcbmu/OneDrive - UC Irvine/Academic 2020-21/Spring 2021/BANA 275/Python/HW 1/output/fp.txt','r',encoding='utf-8')\n",
    "tp = open('C:/Users/fcbmu/OneDrive - UC Irvine/Academic 2020-21/Spring 2021/BANA 275/Python/HW 1/output/tp.txt','r',encoding='utf-8')\n",
    "tn = open('C:/Users/fcbmu/OneDrive - UC Irvine/Academic 2020-21/Spring 2021/BANA 275/Python/HW 1/output/tn.txt','r',encoding='utf-8')\n",
    "fn_count = len(fn.readlines())\n",
    "fp_count= len(fp.readlines())\n",
    "tp_count= len(tp.readlines())\n",
    "tn_count= len(tn.readlines())\n",
    "#print(fn_count)\n",
    "#print(fp_count)\n",
    "#print(tp_count)\n",
    "#print(tn_count)\n",
    "total = fp_count + fn_count+tp_count+tn_count\n",
    "total\n",
    "#Confusion Matrix\n",
    "print(\"Confusion Matrix\")\n",
    "print(\"TP: \",tp_count,\", TN: \",tn_count)\n",
    "print(\"FP: \",fp_count,\", FN: \",fn_count)\n",
    "print()\n",
    "print(\"Confusion Matrix\")\n",
    "print(\"TP: \",round(tp_count/total,2),\", TN: \",round(tn_count/total,2))\n",
    "print(\"FP: \",round(fp_count/total,2),\", FN: \",round(fn_count/total,2))\n",
    "print()\n",
    "print(\"Precision: \",round(tp_count/(tp_count+fp_count),2))\n",
    "print(\"Recall: \",round(tp_count/(tp_count+fn_count),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis, debugging classify on a single example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "\n",
    "\n",
    "def get_error_type(pred, label):\n",
    "    # return the type of error: tp,fp,tn,fn\n",
    "    if pred == 1 and label == 1:\n",
    "        return 'tp'\n",
    "    elif pred == 1 and label == 0:\n",
    "        return 'fp'\n",
    "    elif pred == 0 and label == 1:\n",
    "        return 'fn'\n",
    "    elif pred == 0 and label == 0:\n",
    "        return 'tn'\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "term_count = {}\n",
    "term_sentiment = {}\n",
    "\n",
    "def top_terms(text, inqtabs_dict,swn_dict): #used to update dictionary, not to be applied into 'classify' function\n",
    "    #clean up text\n",
    "    regex_clean_html = re.compile(r'<.*?>') # Remove any HTML tags\n",
    "    clean = re.sub(regex_clean_html, '', text)\n",
    "    regex = r'[A-Za-z]{3,}\\b' #You'll probably want to update this regular expression\n",
    "    words = re.findall(regex, clean) # Extract word from a text\n",
    "    \n",
    "    positive_words_inqtabs = []\n",
    "    negative_words_inqtabs = []\n",
    "    words_matched_inqtabs = []\n",
    "    positive_words_swn = {}\n",
    "    negative_words_swn = {}\n",
    "    positive_words_swn_count = []\n",
    "    negative_words_swn_count = []\n",
    "    words_matched_swn = []\n",
    "    \n",
    "    # Stopwords\n",
    "    stopword = stopwords.words('english')\n",
    "    words_lower = [x.lower() for x in words] # lower case\n",
    "    words_rm = [x for x in words_lower if x not in stopword] # remove stopwords\n",
    "    \n",
    "    for word in words_rm:\n",
    "        word = word.lower()  #You can do other preprocessing here like remove punctuation, etc\n",
    "        if word in inqtabs_dict:\n",
    "            if inqtabs_dict[word] == '1':\n",
    "                positive_words_inqtabs.append(word)\n",
    "            else:\n",
    "                negative_words_inqtabs.append(word)\n",
    "            words_matched_inqtabs.append(word)\n",
    "        if word not in inqtabs_dict and word in swn_dict:\n",
    "            positive_words_swn[word] = swn_dict[word][0]\n",
    "            negative_words_swn[word] = swn_dict[word][1]\n",
    "            words_matched_swn.append(word)\n",
    "\n",
    "        \n",
    "        if word not in term_count:\n",
    "            term_count[word] = 1\n",
    "        else:\n",
    "            term_count[word] += 1\n",
    "\n",
    "#built for inqtabs_dict\n",
    "    sorted_pos = positive_words_inqtabs\n",
    "    sorted_neg = negative_words_inqtabs\n",
    "# #built for swn_dict\n",
    "#     sorted_pos = sorted(positive_words_swn.items(), key=lambda x: x[1], reverse=True)\n",
    "#     sorted_neg = sorted(negative_words_swn.items(), key=lambda x: x[1], reverse=True)\n",
    "#     n = 20\n",
    "#     print(sorted_pos)\n",
    "#     print()\n",
    "#     print(sorted_neg)\n",
    "    \n",
    "    \n",
    "#     print(\"Positive words found: \", len(positive_words_swn), sorted(positive_words_swn.items(), key=lambda x: x[1], reverse=True))\n",
    "#     print(\"Total positive sentiment: \", sum(positive_words_swn.values()))\n",
    "#     print(\"\\nNegative words scores: \", len(negative_words_swn), sorted(negative_words_swn.items(), key=lambda x: x[1], reverse=True))\n",
    "#     print(\"Total negative sentiment:\", sum(negative_words_swn.values()))\n",
    "    return sorted_pos,sorted_neg    \n",
    "\n",
    "#Put the code under the classify method here.  Here's some code to start you off\n",
    "def classify(text, inqtabs_dict, swn_dict):\n",
    "    regex_clean_html = re.compile(r'<.*?>') # Remove any HTML tags\n",
    "    clean = re.sub(regex_clean_html, '', text)\n",
    "    regex = r'[A-Za-z]{3,}\\b' #You'll probably want to update this regular expression\n",
    "    words = re.findall(regex, clean) # Extract word from a text\n",
    "    inqtabs_dict['fun'] = 1\n",
    "#     del inqtabs_dict['get']\n",
    "    \n",
    "    aa_temp = list(swn_dict['dog'])\n",
    "    aa_temp[0],aa_temp[1] = 1,0\n",
    "    swn_dict['dog'] = tuple(aa_temp)\n",
    "    \n",
    "    aa_temp = list(swn_dict['kill'])\n",
    "    aa_temp[0],aa_temp[1] = 0,swn_dict['kill'][1]\n",
    "    swn_dict['kill'] = tuple(aa_temp)\n",
    "    \n",
    "    aa_temp = list(swn_dict['good'])\n",
    "    aa_temp[0],aa_temp[1] = swn_dict['good'][1],0\n",
    "    swn_dict['good'] = tuple(aa_temp)\n",
    "    \n",
    "    positive_words_inqtabs = []\n",
    "    negative_words_inqtabs = []\n",
    "    positive_words_inqtabs_count = 0\n",
    "    negative_words_inqtabs_count = 0    \n",
    "    \n",
    "    words_matched_inqtabs = []\n",
    "    positive_words_swn = {}\n",
    "    negative_words_swn = {}\n",
    "    positive_words_swn_count = []\n",
    "    negative_words_swn_count = []\n",
    "    words_matched_swn = []\n",
    "    \n",
    "    # Stopwords\n",
    "    stopword = stopwords.words('english')\n",
    "    words_lower = [x.lower() for x in words] # lower case\n",
    "    words_rm = [x for x in words_lower if x not in stopword] # remove stopwords\n",
    "  \n",
    "#tokenize, pos tagging, lemmatize\n",
    "#     sentences = \" \".join(words_rm)\n",
    "#     tokens = nltk.word_tokenize(sentences)\n",
    "#     tag_map = defaultdict(lambda : wordnet.NOUN)\n",
    "#     tag_map['J'] = wordnet.ADJ\n",
    "#     tag_map['V'] = wordnet.VERB\n",
    "#     tag_map['R'] = wordnet.ADV\n",
    "#     word_list = []\n",
    "#     for token,tag in pos_tag(tokens):\n",
    "#         lemma = lemmatizer.lemmatize(token, tag_map[tag[0]])\n",
    "#         word_list.append(lemma)  \n",
    "    \n",
    "    for word in words_rm:\n",
    "        #word = word.lower()  #You can do other preprocessing here like remove punctuation, etc\n",
    "        if word in inqtabs_dict:\n",
    "            if inqtabs_dict[word] == '1':\n",
    "                positive_words_inqtabs_count += 1\n",
    "            else:\n",
    "                negative_words_inqtabs_count += 1\n",
    "            words_matched_inqtabs.append(word)\n",
    "        if (word not in inqtabs_dict and word in swn_dict):\n",
    "            positive_words_inqtabs_count += (swn_dict[word][0])**3\n",
    "            negative_words_inqtabs_count += (swn_dict[word][1])**3\n",
    "            words_matched_swn.append(word)\n",
    "\n",
    "    pos_cnt = positive_words_inqtabs_count + 1\n",
    "    neg_cnt = negative_words_inqtabs_count + 1\n",
    "    if ((pos_cnt / neg_cnt) >1.47):\n",
    "        score = 1\n",
    "    else:\n",
    "        score = 0\n",
    "\n",
    "#     print(\"Original text: \", text)\n",
    "#     print(\"Words in text: \", words)\n",
    "#     print(\"\\nScores from Lexicon 1 (Harvard Inquirer)\")\n",
    "#     print(\"Positive words found: \", len(positive_words_inqtabs), positive_words_inqtabs)\n",
    "#     print(\"Negative words found: \", len(negative_words_inqtabs), negative_words_inqtabs)\n",
    "#     print(\"\\nScores from Lexicon 2 (SentiWordNet)\")\n",
    "#     print(\"Positive words found: \", len(positive_words_swn), sorted(positive_words_swn.items(), key=lambda x: x[1], reverse=True))\n",
    "#     print(\"Total positive sentiment: \", sum(positive_words_swn.values()))\n",
    "#     print(\"\\nNegative words scores: \", len(negative_words_swn), sorted(negative_words_swn.items(), key=lambda x: x[1], reverse=True))\n",
    "#     print(\"Total negative sentiment:\", sum(negative_words_swn.values()))\n",
    "#     print(\"\\nScore: \", score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modify this to see it on a different example\n",
    "text = '''\n",
    "Arguably this is a very good \"sequel\", better than the first live action film 101 Dalmatians. It has good dogs, good actors, good jokes and all right slapstick! <br /><br />Cruella DeVil, who has had some rather major therapy, is now a lover of dogs and very kind to them. Many, including Chloe Simon, owner of one of the dogs that Cruella once tried to kill, do not believe this. Others, like Kevin Shepherd (owner of 2nd Chance Dog Shelter) believe that she has changed. <br /><br />Meanwhile, Dipstick, with his mate, have given birth to three cute dalmatian puppies! Little Dipper, Domino and Oddball...<br /><br />Starring Eric Idle as Waddlesworth (the hilarious macaw), Glenn Close as Cruella herself and Gerard Depardieu as Le Pelt (another baddie, the name should give a clue), this is a good family film with excitement and lots more!! One downfall of this film is that is has a lot of painful slapstick, but not quite as excessive as the last film. This is also funnier than the last film.<br /><br />Enjoy \"102 Dalmatians\"! :-)\n",
    "'''\n",
    "classify(text, inqtabs_dict, swn_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_terms(text, inqtabs_dict, swn_dict)\n",
    "aa_temp = list(swn_dict['dog'])\n",
    "print(aa_temp)\n",
    "aa_temp[0],aa_temp[1] = 1,0\n",
    "swn_dict['dog'] = tuple(aa_temp)\n",
    "swn_dict['dog']\n",
    "\n",
    "\n",
    "\n",
    "# swn_dict['dog'][0] = 1\n",
    "# swn_dict['dog'][1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_terms(text, inqtabs_dict, swn_dict)\n",
    "aa_temp = list(swn_dict['kill'])\n",
    "print(aa_temp)\n",
    "aa_temp[0],aa_temp[1] = 0,swn_dict['kill'][1]\n",
    "swn_dict['kill'] = tuple(aa_temp)\n",
    "swn_dict['kill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_temp = list(swn_dict['good'])\n",
    "print(aa_temp)\n",
    "aa_temp[0],aa_temp[1] = swn_dict['good'][1],0\n",
    "swn_dict['good'] = tuple(aa_temp)\n",
    "swn_dict['good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del inqtabs_dict['get']\n",
    "# inqtabs_dict['dog']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything below this cell is meant to identify (by descending count) most frequent terms and their respective sentiment (pos or neg) scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "temp_data_1 = data[0:5000]\n",
    "temp_data_2 = data[5000:1000]\n",
    "temp_data_3 = data[10000:15000]\n",
    "temp_data_4 = data[15000:20000]\n",
    "temp_data_5 = data[20000:250001]\n",
    "\n",
    "neg_word_dict_count = {}\n",
    "pos_word_dict_count = {}\n",
    "# print(temp_data)\n",
    "print()\n",
    "# temp = [{'FileIndex': '901', 'Category': '1', 'Review': 'NEW WORLD ORDER BOYS BOYS One of my favorite scenes One One One is at the beginning when guests on a private yacht decide to take an impromptu swim - in their underwear! Rather risqué for 1931!'}]\n",
    "\n",
    "sorted_pos = []\n",
    "sorted_neg = []\n",
    "\n",
    "#identify tuples and append them to a new list\n",
    "def append_dict(df_list):\n",
    "    for row in df_list:\n",
    "        sorted_pos_list,sorted_neg_list = top_terms(row['Review'], inqtabs_dict, swn_dict)\n",
    "        sorted_pos.extend(sorted_pos_list)\n",
    "        sorted_neg.extend(sorted_neg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sorted_pos = []\n",
    "sorted_neg = []\n",
    "append_dict(temp_data_1)\n",
    "append_dict(temp_data_2)\n",
    "append_dict(temp_data_3)\n",
    "append_dict(temp_data_4)\n",
    "append_dict(temp_data_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view list\n",
    "sorted_neg_count_dict = {}\n",
    "for word in sorted_neg:\n",
    "    if word not in sorted_neg_count_dict:\n",
    "        sorted_neg_count_dict[word] = 1\n",
    "    else:\n",
    "        sorted_neg_count_dict[word] += 1\n",
    "sorted_neg = dict(sorted(sorted_neg_count_dict.items(), key=lambda item: item[1], reverse = True))\n",
    "sorted_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_pos_count_dict = {}\n",
    "for word in sorted_pos:\n",
    "    if word not in sorted_pos_count_dict:\n",
    "        sorted_pos_count_dict[word] = 1\n",
    "    else:\n",
    "        sorted_pos_count_dict[word] += 1\n",
    "sorted_pos = dict(sorted(sorted_pos_count_dict.items(), key=lambda item: item[1], reverse = True))\n",
    "sorted_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words to update:\n",
    "# Possible words to update: one\n",
    "#Consider re-scoring words in both list / making them both zero (i.e. they may be more common in positive texts when really they are used negativly. vice versa)\n",
    "#consider words with a zero score which should have a value\n",
    "#consider making some words mutually exclusive to one sentiment (i.e. 'one' has a value of 0.5 for both sentiment types when it likely has no negative or positive connotation)\n",
    "#consider term count (righ tnow its removing all duplicates)\n",
    "#using swn dictionary reduced accuracy to 50%, using swn dictionary with duplicate terms reduced accuracy to ~55%\n",
    "\n",
    "# Non-lemmatized thresholds:\n",
    "#     if ((pos_cnt / neg_cnt) >1.7): accuracy 66.392%\n",
    "#     if ((pos_cnt / neg_cnt) >1.55): accuracy 66.92%\n",
    "#     if ((pos_cnt / neg_cnt) >1.5): accuracy 66.97%\n",
    "#     if ((pos_cnt / neg_cnt) >1.49): accuracy 67.14%\n",
    "#     if ((pos_cnt / neg_cnt) >1.47): accuracy 67.14% #optimal\n",
    "#     if ((pos_cnt / neg_cnt) >1.45): accuracy 67.1%\n",
    "#     if ((pos_cnt / neg_cnt) >1.4): accuracy 66.93%\n",
    "#     if ((pos_cnt / neg_cnt) >1.25): accuracy 64%\n",
    "\n",
    "#lemmatized threshold accuracy #lemmatizing appears to decrease accuracy\n",
    "#     if ((pos_cnt / neg_cnt) >1.47): accuracy 66.348\n",
    "\n",
    "#non_lemmatized threshold with inqtabs_dict[fun' == 1]\n",
    "#     if ((pos_cnt / neg_cnt) >1.47): accuracy 67.14% #optimal\n",
    "\n",
    "#non-lemmatized with inqtabs_dict[fun' == 1] using both dictionaries\n",
    "#     if ((pos_cnt / neg_cnt) >1.47): accuracy 66.504%\n",
    "\n",
    "#non-lemmatized with inqtabs_dict[fun' == 1] using both dictionaries with swn value ^2\n",
    "#     if ((pos_cnt / neg_cnt) >1.47): accuracy %67.096\n",
    "\n",
    "#non-lemmatized with inqtabs_dict[fun' == 1] using both dictionaries with swn value ^3\n",
    "#     if ((pos_cnt / neg_cnt) >1.47): accuracy %67.304\n",
    "\n",
    "#non-lemmatized with inqtabs_dict[fun' == 1] using both dictionaries with swn value ^10\n",
    "#     if ((pos_cnt / neg_cnt) >1.47): accuracy %67.304\n",
    "#non-lemmatized with inqtabs_dict[fun' == 1] using both dictionaries with swn value ^10 update 'get', kill, dog\n",
    "#     if ((pos_cnt / neg_cnt) >1.47): accuracy %67.304\n",
    "#non-lemmatized with inqtabs_dict[fun' == 1] using both dictionaries with swn value multiple 2 update inq:'fun',update swn: 'get', kill, dog\n",
    "#     if ((pos_cnt / neg_cnt) >1.47): accuracy %67.304"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
